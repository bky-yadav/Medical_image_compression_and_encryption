{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ================= INSTALL PYTHON PACKAGES =================\n",
        "!pip install -q \\\n",
        "    opencv-python-headless \\\n",
        "    opencv-python \\\n",
        "    pydicom \\\n",
        "    scikit-image \\\n",
        "    pillow \\\n",
        "    matplotlib \\\n",
        "    kagglehub[pandas-datasets]\n",
        "\n",
        "# ================= INSTALL SYSTEM DEPENDENCIES =================\n",
        "!apt-get -qq update\n",
        "!apt-get -qq install -y cmake ninja-build gcc g++ libssl-dev\n",
        "\n",
        "# ================= INSTALL liboqs-python =================\n",
        "%cd /content\n",
        "!rm -rf liboqs-python\n",
        "!git clone --depth 1 https://github.com/open-quantum-safe/liboqs-python.git\n",
        "%cd liboqs-python\n",
        "!pip install -q ."
      ],
      "metadata": {
        "id": "YyzF3KoIPjOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import oqs\n",
        "\n",
        "\n",
        "with oqs.KeyEncapsulation(\"ML-KEM-768\") as kem_receiver:\n",
        "    public_key = kem_receiver.generate_keypair()\n",
        "\n",
        "\n",
        "    with oqs.KeyEncapsulation(\"ML-KEM-768\") as kem_sender:\n",
        "        ciphertext, shared_secret_sender = kem_sender.encap_secret(public_key)\n",
        "\n",
        "\n",
        "    shared_secret_receiver = kem_receiver.decap_secret(ciphertext)\n",
        "\n",
        "    print(\"ML-KEM-768 works\")\n",
        "    print(\"Shared secret match:\", shared_secret_sender == shared_secret_receiver)\n",
        "    print(\"Shared secret length:\", len(shared_secret_sender))\n"
      ],
      "metadata": {
        "id": "sldFPg19PmV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#download dataset from kaggle\n",
        "import os\n",
        "import kagglehub\n",
        "\n",
        "\n",
        "dataset_path = kagglehub.dataset_download(\"unidpro/brain-cancer-dataset\")\n",
        "print(\"Dataset path:\", dataset_path)\n",
        "\n",
        "\n",
        "dicom_files = []\n",
        "\n",
        "for root, _, files in os.walk(dataset_path):\n",
        "    for f in files:\n",
        "        if f.lower().endswith(\".dcm\"):\n",
        "            dicom_files.append(os.path.join(root, f))\n",
        "\n",
        "print(f\"Total DICOM images found: {len(dicom_files)}\")\n",
        "\n",
        "\n",
        "dicom_files[:5]\n"
      ],
      "metadata": {
        "id": "tLrExXidPovT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import pydicom\n",
        "import os\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr, structural_similarity as ssim\n",
        "from typing import Dict, Tuple\n",
        "from PIL import Image\n",
        "import io\n",
        "import hashlib\n",
        "import json\n",
        "from datetime import datetime\n",
        "import sys\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Block:\n",
        "    def __init__(self, timestamp, data, previous_hash):\n",
        "        self.timestamp = timestamp\n",
        "        self.data = data\n",
        "        self.previous_hash = previous_hash\n",
        "        self.hash = self.calculate_hash()\n",
        "\n",
        "    def calculate_hash(self):\n",
        "        \"\"\"Calculates the hash of the block.\"\"\"\n",
        "        block_string = str(self.timestamp) + str(self.data) + str(self.previous_hash)\n",
        "        return hashlib.sha256(block_string.encode()).hexdigest()\n",
        "\n",
        "class Blockchain:\n",
        "    def __init__(self):\n",
        "\n",
        "        self.chain = [self.create_genesis_block()]\n",
        "\n",
        "    def create_genesis_block(self):\n",
        "        \"\"\"Creates the very first block in the chain.\"\"\"\n",
        "        return Block(datetime.now(), \"Genesis Block\", \"0\")\n",
        "\n",
        "    def get_latest_block(self):\n",
        "        \"\"\"Returns the most recent block in the chain.\"\"\"\n",
        "        return self.chain[-1]\n",
        "\n",
        "    def add_block(self, new_data):\n",
        "        \"\"\"Adds a new block to the chain.\"\"\"\n",
        "        latest_block = self.get_latest_block()\n",
        "        new_block = Block(\n",
        "            timestamp=datetime.now(),\n",
        "            data=new_data,\n",
        "            previous_hash=latest_block.hash\n",
        "        )\n",
        "        self.chain.append(new_block)\n",
        "        print(\" New block added to the chain with key hash:\", new_data)\n",
        "\n",
        "    def is_chain_valid(self):\n",
        "        \"\"\"Validates the integrity of the entire blockchain.\"\"\"\n",
        "        for i in range(1, len(self.chain)):\n",
        "            current_block = self.chain[i]\n",
        "            previous_block = self.chain[i-1]\n",
        "\n",
        "            if current_block.hash != current_block.calculate_hash():\n",
        "                return False\n",
        "            if current_block.previous_hash != previous_block.hash:\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "class dcmCompressor:\n",
        "    def __init__(self, j2k_quality=90, epsilon=1/512):\n",
        "        self.j2k_quality = j2k_quality\n",
        "        self.epsilon = epsilon\n",
        "        self.original_pixel_data = None\n",
        "        self.metadata = {}\n",
        "\n",
        "\n",
        "    def _extract_metadata(self, dcm):\n",
        "        self.metadata = {\n",
        "            'Modality': dcm.get('Modality', 'UN'),\n",
        "            'BitsStored': dcm.get('BitsStored', 12),\n",
        "            'TransferSyntaxUID': dcm.file_meta.TransferSyntaxUID if hasattr(dcm, 'file_meta') else '',\n",
        "            'PhotometricInterpretation': dcm.get('PhotometricInterpretation', 'MONOCHROME2'),\n",
        "            'Rows': dcm.Rows,\n",
        "            'Columns': dcm.Columns\n",
        "        }\n",
        "\n",
        "    def _convert_complex_to_magnitude(self, pixel_array):\n",
        "        if np.iscomplexobj(pixel_array):\n",
        "            print(\"Converting complex SWI data to magnitude\")\n",
        "            return np.abs(pixel_array)\n",
        "        return pixel_array\n",
        "\n",
        "    def _normalize_pixel_data(self, pixel_array, bits_stored):\n",
        "        max_val = 2**bits_stored - 1\n",
        "        return pixel_array.astype(np.float32) / max_val\n",
        "\n",
        "    def _denormalize_pixel_data(self, normalized_array, bits_stored):\n",
        "        max_val = 2**bits_stored - 1\n",
        "        return (normalized_array * max_val).astype(np.uint16)\n",
        "\n",
        "    def _jpeg2000_compress(self, image, quality_mode='dB'):\n",
        "        img_uint16 = self._denormalize_pixel_data(image, self.metadata['BitsStored'])\n",
        "        img_pil = Image.fromarray(img_uint16)\n",
        "        buf = io.BytesIO()\n",
        "        img_pil.save(buf, format='JPEG2000',\n",
        "            quality_mode=quality_mode,\n",
        "            quality_layers=[self.j2k_quality])\n",
        "        buf.seek(0)\n",
        "        decompressed = np.array(Image.open(buf)).astype(np.float32)\n",
        "        decompressed = self._normalize_pixel_data(decompressed, self.metadata['BitsStored'])\n",
        "        return buf.getvalue(), decompressed\n",
        "\n",
        "    def _calculate_residual(self, original, compressed):\n",
        "        residual = original - compressed\n",
        "\n",
        "\n",
        "        residual = np.clip(residual, -self.epsilon, +self.epsilon)\n",
        "\n",
        "\n",
        "        max_abs = np.max(np.abs(residual))\n",
        "        if max_abs > 0:\n",
        "            residual_scaled = residual / max_abs\n",
        "        else:\n",
        "            residual_scaled = residual\n",
        "\n",
        "        return residual_scaled\n",
        "\n",
        "\n",
        "    def _reconstruct_from_residual(self, compressed, residual):\n",
        "        residual_restored = residual * np.max(np.abs(self.original_pixel_data - compressed))\n",
        "        return np.clip(compressed + residual_restored, 0, 1)\n",
        "\n",
        "    def compress(self, filepath):\n",
        "        try:\n",
        "            dcm = pydicom.dcmread(filepath, force=True)\n",
        "            self._extract_metadata(dcm)\n",
        "            pixel_array = dcm.pixel_array\n",
        "            pixel_array = self._convert_complex_to_magnitude(pixel_array)\n",
        "            self.original_pixel_data = self._normalize_pixel_data(pixel_array, self.metadata['BitsStored'])\n",
        "\n",
        "            j2k_data, j2k_recon = self._jpeg2000_compress(self.original_pixel_data)\n",
        "            residual = self._calculate_residual(self.original_pixel_data, j2k_recon)\n",
        "            residual_data, _ = self._jpeg2000_compress(residual, quality_mode='rates')\n",
        "\n",
        "            return {\n",
        "                'metadata': self.metadata,\n",
        "                'j2k_primary': j2k_data,\n",
        "                'j2k_residual': residual_data,\n",
        "                'compression_ratio': len(dcm.PixelData) / (len(j2k_data) + len(residual_data))\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f\"Compression failed for {filepath}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def decompress(self, compressed_data):\n",
        "        try:\n",
        "            buf = io.BytesIO(compressed_data['j2k_primary'])\n",
        "            primary_img = np.array(Image.open(buf)).astype(np.float32)\n",
        "            primary_img = self._normalize_pixel_data(primary_img, compressed_data['metadata']['BitsStored'])\n",
        "\n",
        "            buf = io.BytesIO(compressed_data['j2k_residual'])\n",
        "            residual_img = np.array(Image.open(buf)).astype(np.float32)\n",
        "            residual_img = residual_img / 32767.0\n",
        "\n",
        "            reconstructed = self._reconstruct_from_residual(primary_img, residual_img)\n",
        "            return reconstructed\n",
        "        except Exception as e:\n",
        "            print(f\"Decompression failed: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def evaluate(self, filepath):\n",
        "        compressed = self.compress(filepath)\n",
        "        if not compressed:\n",
        "            return None\n",
        "\n",
        "        reconstructed = self.decompress(compressed)\n",
        "        if reconstructed is None:\n",
        "            return None\n",
        "\n",
        "        metrics = {\n",
        "            'filename': os.path.basename(filepath),\n",
        "            'psnr': psnr(self.original_pixel_data, reconstructed, data_range=1.0),\n",
        "            'ssim': ssim(self.original_pixel_data, reconstructed,\n",
        "                data_range=1.0, win_size=3, channel_axis=None),\n",
        "            'compression_ratio': compressed['compression_ratio'],\n",
        "            'original_size': len(pydicom.dcmread(filepath).PixelData),\n",
        "            'compressed_size': len(compressed['j2k_primary']) + len(compressed['j2k_residual'])\n",
        "    }\n",
        "\n",
        "\n",
        "        return metrics\n",
        "\n",
        "class MedicalImageEncryptor:\n",
        "    \"\"\"\n",
        "    Medical Image Encryption Framework using:\n",
        "    - Enhanced Memristive Hyperchaotic Key Generator\n",
        "    - Hybrid Permutation\n",
        "    - Bidirectional Diffusion\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.encryption_key = None\n",
        "\n",
        "    def enhanced_memristive_chaotic_generator(self, x0, y0, z0, w0,a, b, c, d, e, size) -> np.ndarray:\n",
        "        \"\"\"\n",
        "         Generate chaotic key stream using a 4D memristive hyperchaotic system.\n",
        "        \"\"\"\n",
        "        x, y, z, w = x0, y0, z0, w0\n",
        "        dt = 0.005\n",
        "\n",
        "\n",
        "        for _ in range(2000):\n",
        "            dx = a*(y - x) + w + e*x*z\n",
        "            dy = b*x - x*z + c*y\n",
        "            dz = x*y - d*z\n",
        "            dw = -x - e*w\n",
        "            x, y, z, w = x + dt*dx, y + dt*dy, z + dt*dz, w + dt*dw\n",
        "\n",
        "\n",
        "        key_stream = np.zeros(size, dtype=np.uint8)\n",
        "        for i in range(size):\n",
        "            dx = a*(y - x) + w + e*x*z\n",
        "            dy = b*x - x*z + c*y\n",
        "            dz = x*y - d*z\n",
        "            dw = -x - e*w\n",
        "            x, y, z, w = x + dt*dx, y + dt*dy, z + dt*dz, w + dt*dw\n",
        "            val = int(abs(x*1e5 + y*1e4 + z*1e3 + w*1e2)) % 256\n",
        "            key_stream[i] = val\n",
        "        return key_stream\n",
        "\n",
        "\n",
        "    def hybrid_permutation(self, image_array: np.ndarray, key_stream: np.ndarray) -> np.ndarray:\n",
        "        rows, cols = image_array.shape\n",
        "        total = rows * cols\n",
        "        flat = image_array.flatten()\n",
        "\n",
        "        random_order = np.argsort(key_stream[:total])\n",
        "        permuted = flat[random_order]\n",
        "        return permuted.reshape(rows, cols)\n",
        "\n",
        "    def reverse_hybrid_permutation(self, image_array: np.ndarray, key_stream: np.ndarray) -> np.ndarray:\n",
        "        rows, cols = image_array.shape\n",
        "        total = rows * cols\n",
        "        flat = image_array.flatten()\n",
        "\n",
        "        random_order = np.argsort(key_stream[:total])\n",
        "        original = np.zeros_like(flat)\n",
        "        original[random_order] = flat\n",
        "        return original.reshape(rows, cols)\n",
        "\n",
        "\n",
        "    def bidirectional_diffusion(self, image_array: np.ndarray, key_stream: np.ndarray, rounds=2) -> np.ndarray:\n",
        "        diffused = image_array.copy().astype(np.int32)\n",
        "        rows, cols = diffused.shape\n",
        "        flat_size = rows * cols\n",
        "\n",
        "        for _ in range(rounds):\n",
        "\n",
        "            for i in range(flat_size):\n",
        "              r, c = i // cols, i % cols\n",
        "              key_val = int(key_stream[i % len(key_stream)])\n",
        "              left = diffused[r, (c-1) % cols]\n",
        "              up = diffused[(r-1) % rows, c]\n",
        "              prev = diffused[(i-1) // cols, (i-1) % cols] if i > 0 else 0\n",
        "              mix = (key_val ^ r ^ c ^ left ^ up ^ prev) & 0xFF\n",
        "              diffused[r, c] = (diffused[r, c] ^ mix) & 0xFF\n",
        "\n",
        "\n",
        "            for i in range(flat_size-1, -1, -1):\n",
        "              r, c = i // cols, i % cols\n",
        "              key_val = int(key_stream[i % len(key_stream)])\n",
        "              right = diffused[r, (c+1) % cols]\n",
        "              down = diffused[(r+1) % rows, c]\n",
        "              nxt = diffused[(i+1) // cols, (i+1) % cols] if i < flat_size-1 else 0\n",
        "              mix = (key_val ^ r ^ c ^ right ^ down ^ nxt) & 0xFF\n",
        "              diffused[r, c] = (diffused[r, c] ^ mix) & 0xFF\n",
        "\n",
        "        return diffused.astype(np.uint8)\n",
        "\n",
        "    def reverse_bidirectional_diffusion(self, image_array: np.ndarray, key_stream: np.ndarray, rounds=2) -> np.ndarray:\n",
        "        undiffused = image_array.copy().astype(np.int32)\n",
        "        rows, cols = undiffused.shape\n",
        "        flat_size = rows * cols\n",
        "\n",
        "        for _ in range(rounds):\n",
        "\n",
        "            for i in range(flat_size):\n",
        "                r, c = i // cols, i % cols\n",
        "                key_val = int(key_stream[i % len(key_stream)])\n",
        "                right = undiffused[r, (c+1) % cols]\n",
        "                down = undiffused[(r+1) % rows, c]\n",
        "                nxt = undiffused[(i+1) // cols, (i+1) % cols] if i < flat_size-1 else 0\n",
        "                mix = (key_val ^ r ^ c ^ right ^ down ^ nxt) & 0xFF\n",
        "                undiffused[r, c] = (undiffused[r, c] ^ mix) & 0xFF\n",
        "\n",
        "            for i in range(flat_size-1, -1, -1):\n",
        "                r, c = i // cols, i % cols\n",
        "                key_val = int(key_stream[i % len(key_stream)])\n",
        "                left = undiffused[r, (c-1) % cols]\n",
        "                up = undiffused[(r-1) % rows, c]\n",
        "                prev = undiffused[(i-1) // cols, (i-1) % cols] if i > 0 else 0\n",
        "                mix = (key_val ^ r ^ c ^ left ^ up ^ prev) & 0xFF\n",
        "                undiffused[r, c] = (undiffused[r, c] ^ mix) & 0xFF\n",
        "\n",
        "        return undiffused.astype(np.uint8)\n",
        "\n",
        "\n",
        "    def encrypt_image(self, image_array: np.ndarray, key_params: Dict=None) -> Tuple[np.ndarray, Dict]:\n",
        "        if len(image_array.shape) == 3:\n",
        "            encrypted_channels, params = [], None\n",
        "            for i in range(3):\n",
        "                encrypted, params = self.encrypt_image(image_array[:, :, i], key_params)\n",
        "                encrypted_channels.append(encrypted)\n",
        "            return np.stack(encrypted_channels, axis=2), params\n",
        "\n",
        "        if key_params is None:\n",
        "            key_params = {\n",
        "                'x0': random.random(), 'y0': random.random(),\n",
        "                'z0': random.random(), 'w0': random.random(),\n",
        "                'a': 35.0 + random.random()*5,\n",
        "                'b': 3.0 + random.random(),\n",
        "                'c': 12.0 + random.random()*2,\n",
        "                'd': 7.0 + random.random(),\n",
        "                'e': 0.1 + random.random()*0.1\n",
        "        }\n",
        "\n",
        "\n",
        "        seed = int(np.sum(image_array)) % 1000\n",
        "        key_params = key_params.copy()\n",
        "        key_params['seed'] = seed\n",
        "        key_params['x0'] = (key_params['x0'] + seed) % 1\n",
        "        key_params['y0'] = (key_params['y0'] + seed/2) % 1\n",
        "        key_params['z0'] = (key_params['z0'] + seed/3) % 1\n",
        "        key_params['w0'] = (key_params['w0'] + seed/4) % 1\n",
        "\n",
        "        rows, cols = image_array.shape\n",
        "        total_pixels = rows * cols\n",
        "        key_stream = self.enhanced_memristive_chaotic_generator(\n",
        "            key_params['x0'], key_params['y0'], key_params['z0'], key_params['w0'],\n",
        "            key_params['a'], key_params['b'], key_params['c'], key_params['d'], key_params['e'],\n",
        "            total_pixels*2\n",
        "        )\n",
        "\n",
        "        permuted = self.hybrid_permutation(image_array, key_stream[:total_pixels])\n",
        "        encrypted = self.bidirectional_diffusion(permuted, key_stream[total_pixels:], rounds=2)\n",
        "        self.encryption_key = key_params\n",
        "        return encrypted, key_params\n",
        "\n",
        "    def decrypt_image(self, encrypted_array: np.ndarray, key_params: Dict) -> np.ndarray:\n",
        "        if len(encrypted_array.shape) == 3:\n",
        "            decrypted_channels = []\n",
        "            for i in range(3):\n",
        "                decrypted = self.decrypt_image(encrypted_array[:, :, i], key_params)\n",
        "                decrypted_channels.append(decrypted)\n",
        "            return np.stack(decrypted_channels, axis=2)\n",
        "\n",
        "        rows, cols = encrypted_array.shape\n",
        "        total_pixels = rows * cols\n",
        "\n",
        "\n",
        "        key_stream = self.enhanced_memristive_chaotic_generator(\n",
        "            key_params['x0'], key_params['y0'], key_params['z0'], key_params['w0'],\n",
        "            key_params['a'], key_params['b'], key_params['c'], key_params['d'], key_params['e'],\n",
        "            total_pixels*2\n",
        "        )\n",
        "\n",
        "        undiffused = self.reverse_bidirectional_diffusion(encrypted_array, key_stream[total_pixels:], rounds=2)\n",
        "        decrypted = self.reverse_hybrid_permutation(undiffused, key_stream[:total_pixels])\n",
        "        return decrypted\n",
        "\n",
        "\n",
        "    def calculate_metrics(self, original: np.ndarray, encrypted: np.ndarray, decrypted: np.ndarray) -> Dict:\n",
        "        modified_original = original.copy()\n",
        "        modified_original[0, 0] = (int(modified_original[0, 0]) + 1) % 256\n",
        "        modified_encrypted, _ = self.encrypt_image(modified_original, key_params=self.encryption_key)\n",
        "\n",
        "        diff_matrix = (encrypted != modified_encrypted).astype(np.int32)\n",
        "        npcr = (np.sum(diff_matrix) / original.size) * 100\n",
        "        uaci = (np.sum(np.abs(encrypted.astype(np.int32) - modified_encrypted.astype(np.int32)))\n",
        "                    / (255 * original.size)) * 100\n",
        "\n",
        "        def entropy(img):\n",
        "            hist = np.histogram(img.flatten(), bins=256, range=[0, 256])[0]\n",
        "            prob = hist / np.sum(hist)\n",
        "            prob = prob[prob > 0]\n",
        "            return -np.sum(prob * np.log2(prob))\n",
        "\n",
        "        return {\n",
        "            'NPCR': npcr,\n",
        "            'UACI': uaci,\n",
        "            'Original Entropy': entropy(original),\n",
        "            'Encrypted Entropy': entropy(encrypted)\n",
        "        }\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "H7vSB_go9Yd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#experiment for a single dicom image\n",
        "import hmac\n",
        "import hashlib\n",
        "import secrets\n",
        "import sys\n",
        "import oqs\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pydicom\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr, structural_similarity as ssim\n",
        "import time\n",
        "import statistics\n",
        "\n",
        "\n",
        "def hkdf(ikm: bytes, salt: bytes, info: bytes, length=64):\n",
        "    prk = hmac.new(salt, ikm, hashlib.sha256).digest()\n",
        "    t = b\"\"\n",
        "    okm = b\"\"\n",
        "    c = 1\n",
        "    while len(okm) < length:\n",
        "        t = hmac.new(prk, t + info + bytes([c]), hashlib.sha256).digest()\n",
        "        okm += t\n",
        "        c += 1\n",
        "    return okm[:length]\n",
        "\n",
        "def derive_session_seed(shared_secret, nonce, receiver_id):\n",
        "    return hkdf(shared_secret, nonce, receiver_id, 32)\n",
        "\n",
        "def derive_image_key(session_seed, dcm):\n",
        "    uid_blob = (\n",
        "        dcm.StudyInstanceUID +\n",
        "        dcm.SeriesInstanceUID +\n",
        "        dcm.SOPInstanceUID +\n",
        "        dcm.SOPClassUID\n",
        "    ).encode()\n",
        "    return hkdf(session_seed, b\"DICOM\", uid_blob, 64)\n",
        "\n",
        "def derive_domain_keys(K_img):\n",
        "    return {\n",
        "        \"K_perm_p\": hkdf(K_img, b\"\", b\"perm:primary\", 32),\n",
        "        \"K_diff_p\": hkdf(K_img, b\"\", b\"diff:primary\", 32),\n",
        "        \"K_perm_r\": hkdf(K_img, b\"\", b\"perm:residual\", 32),\n",
        "        \"K_diff_r\": hkdf(K_img, b\"\", b\"diff:residual\", 32),\n",
        "        \"K_mac\":    hkdf(K_img, b\"\", b\"mac\", 32)\n",
        "    }\n",
        "\n",
        "def map_key_to_chaos_params(K_img):\n",
        "    v = [int.from_bytes(K_img[i:i+4], 'big') for i in range(0, 36, 4)]\n",
        "    return {\n",
        "        'x0': 0.1 + (v[0] % 1000) / 10000,\n",
        "        'y0': 0.1 + (v[1] % 1000) / 10000,\n",
        "        'z0': 0.1 + (v[2] % 1000) / 10000,\n",
        "        'w0': 0.1 + (v[3] % 1000) / 10000,\n",
        "        'a': 35.0 + (v[4] % 50) / 10,\n",
        "        'b': 3.0 + (v[5] % 10) / 10,\n",
        "        'c': 12.0 + (v[6] % 20) / 10,\n",
        "        'd': 7.0 + (v[7] % 10) / 10,\n",
        "        'e': 0.1 + (v[8] % 10) / 100\n",
        "    }\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    print(\"Blockchain for Key Validation Initialized.\")\n",
        "\n",
        "    input_filepath = \"image path \"\n",
        "    dcm = pydicom.dcmread(input_filepath, force=True)\n",
        "\n",
        "\n",
        "    compressor = dcmCompressor(j2k_quality=90)\n",
        "    encryptor = MedicalImageEncryptor()\n",
        "\n",
        "    print(\"\\n==================== COMPRESSION ====================\")\n",
        "    compression_results = compressor.compress(input_filepath)\n",
        "    reconstructed = compressor.decompress(compression_results)\n",
        "\n",
        "    print(f\"PSNR : {psnr(compressor.original_pixel_data, reconstructed, data_range=1.0):.2f} dB\")\n",
        "    print(f\"SSIM : {ssim(compressor.original_pixel_data, reconstructed, data_range=1.0):.4f}\")\n",
        "    print(f\"Compression Ratio : {compression_results['compression_ratio']:.3f}\")\n",
        "\n",
        "    compressed_uint8 = cv2.normalize(\n",
        "        reconstructed, None, 0, 255, cv2.NORM_MINMAX\n",
        "    ).astype(np.uint8)\n",
        "\n",
        "\n",
        "    kem_receiver = oqs.KeyEncapsulation(\"ML-KEM-768\")\n",
        "    pk_PQC = kem_receiver.generate_keypair()\n",
        "\n",
        "\n",
        "    print(\"\\n==================== SENDER SIDE ====================\")\n",
        "\n",
        "    nonce = secrets.token_bytes(16)\n",
        "    receiver_id = b\"Receiver-01\"\n",
        "\n",
        "    kem_sender = oqs.KeyEncapsulation(\"ML-KEM-768\")\n",
        "    ct_pqc, shared_secret = kem_sender.encap_secret(pk_PQC)\n",
        "\n",
        "    session_seed = derive_session_seed(shared_secret, nonce, receiver_id)\n",
        "    K_img = derive_image_key(session_seed, dcm)\n",
        "\n",
        "    domain_keys = derive_domain_keys(K_img)\n",
        "    chaos_params = map_key_to_chaos_params(K_img)\n",
        "\n",
        "    encrypted_img, _ = encryptor.encrypt_image(\n",
        "        compressed_uint8, key_params=chaos_params\n",
        "    )\n",
        "\n",
        "    ledger_hash = hashlib.sha256(K_img).hexdigest()\n",
        "\n",
        "\n",
        "    print(\"\\n==================== RECEIVER SIDE ====================\")\n",
        "\n",
        "    shared_secret_rx = kem_receiver.decap_secret(ct_pqc)\n",
        "    assert shared_secret == shared_secret_rx, \" ML-KEM shared secret mismatch\"\n",
        "\n",
        "    session_seed_rx = derive_session_seed(shared_secret_rx, nonce, receiver_id)\n",
        "    K_img_rx = derive_image_key(session_seed_rx, dcm)\n",
        "\n",
        "    chaos_params_rx = map_key_to_chaos_params(K_img_rx)\n",
        "\n",
        "    if hashlib.sha256(K_img_rx).hexdigest() != ledger_hash:\n",
        "        print(\" Key verification failed. Abort.\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    decrypted_img = encryptor.decrypt_image(\n",
        "        encrypted_img, chaos_params_rx\n",
        "    )\n",
        "\n",
        "    print(\" Key verification successful. Decryption completed.\")\n",
        "\n",
        "\n",
        "    metrics = encryptor.calculate_metrics(\n",
        "        compressed_uint8, encrypted_img, decrypted_img\n",
        "    )\n",
        "\n",
        "    print(\"\\n==================== ENCRYPTION METRICS ====================\")\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CTwlfZE0PtoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# running experiment for whole dataset\n",
        "import pydicom\n",
        "import numpy as np\n",
        "import cv2\n",
        "import json\n",
        "import hashlib\n",
        "from collections import defaultdict\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "\n",
        "\n",
        "key_validator_chain = Blockchain()\n",
        "\n",
        "fixed_keys = {\n",
        "    'x0': 0.123456, 'y0': 0.654321, 'z0': 0.246810, 'w0': 0.135791,\n",
        "    'a': 37.5, 'b': 3.5, 'c': 13.2, 'd': 7.8, 'e': 0.15\n",
        "}\n",
        "\n",
        "compressor = dcmCompressor()\n",
        "encryptor = MedicalImageEncryptor()\n",
        "\n",
        "\n",
        "\n",
        "TARGET_RESOLUTIONS = {256, 800, 960}\n",
        "MAX_IMAGES_PER_RES = 20\n",
        "\n",
        "\n",
        "\n",
        "metrics_by_resolution = defaultdict(lambda: {\n",
        "    'psnr': [],\n",
        "    'ssim': [],\n",
        "    'compression_ratio': []\n",
        "})\n",
        "\n",
        "image_count_by_resolution = defaultdict(int)\n",
        "\n",
        "\n",
        "\n",
        "for input_filepath in dicom_files:\n",
        "    try:\n",
        "        dcm = pydicom.dcmread(input_filepath, force=True)\n",
        "        pixel_array = dcm.pixel_array.astype(np.float32)\n",
        "\n",
        "        height, width = pixel_array.shape[:2]\n",
        "\n",
        "\n",
        "        if height != width or height not in TARGET_RESOLUTIONS:\n",
        "            continue\n",
        "\n",
        "        if image_count_by_resolution[height] >= MAX_IMAGES_PER_RES:\n",
        "            continue\n",
        "\n",
        "\n",
        "        compression_results = compressor.compress(input_filepath)\n",
        "        reconstructed = compressor.decompress(compression_results)\n",
        "\n",
        "        psnr_val = psnr(\n",
        "            compressor.original_pixel_data,\n",
        "            reconstructed,\n",
        "            data_range=1.0\n",
        "        )\n",
        "\n",
        "        ssim_val = ssim(\n",
        "            compressor.original_pixel_data,\n",
        "            reconstructed,\n",
        "            data_range=1.0\n",
        "        )\n",
        "\n",
        "\n",
        "        reconstructed_uint8 = cv2.normalize(\n",
        "            reconstructed, None, 0, 255, cv2.NORM_MINMAX\n",
        "        ).astype(np.uint8)\n",
        "\n",
        "        encrypted_img, encryption_keys_used = encryptor.encrypt_image(\n",
        "            reconstructed_uint8, key_params=fixed_keys\n",
        "        )\n",
        "\n",
        "        key_hash = hashlib.sha256(\n",
        "            json.dumps(encryption_keys_used, sort_keys=True).encode()\n",
        "        ).hexdigest()\n",
        "\n",
        "        key_validator_chain.add_block(key_hash)\n",
        "\n",
        "        if key_hash != key_validator_chain.get_latest_block().data:\n",
        "            continue\n",
        "\n",
        "\n",
        "        metrics_by_resolution[height]['psnr'].append(psnr_val)\n",
        "        metrics_by_resolution[height]['ssim'].append(ssim_val)\n",
        "        metrics_by_resolution[height]['compression_ratio'].append(\n",
        "            compression_results['compression_ratio']\n",
        "        )\n",
        "\n",
        "        image_count_by_resolution[height] += 1\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Skipping {input_filepath}: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "final_table = {}\n",
        "\n",
        "for res, metrics in metrics_by_resolution.items():\n",
        "    final_table[res] = {\n",
        "        'count': len(metrics['psnr']),\n",
        "        'PSNR_mean': np.mean(metrics['psnr']),\n",
        "        'PSNR_std': np.std(metrics['psnr']),\n",
        "        'SSIM_mean': np.mean(metrics['ssim']),\n",
        "        'SSIM_std': np.std(metrics['ssim']),\n",
        "        'CR_mean': np.mean(metrics['compression_ratio']),\n",
        "        'CR_std': np.std(metrics['compression_ratio'])\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\n=== Compression Performance (20 Images per Resolution) ===\")\n",
        "\n",
        "for res in sorted(final_table.keys()):\n",
        "    stats = final_table[res]\n",
        "    print(f\"\\nResolution: {res} × {res}\")\n",
        "    print(f\"Images used: {stats['count']}\")\n",
        "    print(f\"PSNR: {stats['PSNR_mean']:.2f} ± {stats['PSNR_std']:.2f} dB\")\n",
        "    print(f\"SSIM: {stats['SSIM_mean']:.4f} ± {stats['SSIM_std']:.4f}\")\n",
        "    print(f\"CR:   {stats['CR_mean']:.2f} ± {stats['CR_std']:.2f}\")\n"
      ],
      "metadata": {
        "id": "l_OcaBVBPxj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compression Performance & Per-Pixel Error Analysis\n",
        "import pydicom\n",
        "import numpy as np\n",
        "import cv2\n",
        "import json\n",
        "import hashlib\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "\n",
        "\n",
        "key_validator_chain = Blockchain()\n",
        "\n",
        "fixed_keys = {\n",
        "    'x0': 0.123456, 'y0': 0.654321, 'z0': 0.246810, 'w0': 0.135791,\n",
        "    'a': 37.5, 'b': 3.5, 'c': 13.2, 'd': 7.8, 'e': 0.15\n",
        "}\n",
        "\n",
        "compressor = dcmCompressor(j2k_quality=90)\n",
        "encryptor = MedicalImageEncryptor()\n",
        "\n",
        "\n",
        "TARGET_RESOLUTIONS = {256, 800, 960}\n",
        "ERROR_PLOT_RES = {256, 800, 960}\n",
        "MAX_IMAGES_PER_RES = 20\n",
        "\n",
        "\n",
        "\n",
        "metrics_by_resolution = defaultdict(lambda: {\n",
        "    'psnr': [],\n",
        "    'ssim': [],\n",
        "    'compression_ratio': [],\n",
        "    'pixel_errors': []\n",
        "})\n",
        "\n",
        "image_count_by_resolution = defaultdict(int)\n",
        "\n",
        "\n",
        "\n",
        "for input_filepath in dicom_files:\n",
        "    try:\n",
        "        dcm = pydicom.dcmread(input_filepath, force=True)\n",
        "        pixel_array = dcm.pixel_array.astype(np.float32)\n",
        "\n",
        "        if pixel_array.ndim != 2:\n",
        "            continue\n",
        "\n",
        "        height, width = pixel_array.shape\n",
        "\n",
        "        if height != width or height not in TARGET_RESOLUTIONS:\n",
        "            continue\n",
        "\n",
        "        if image_count_by_resolution[height] >= MAX_IMAGES_PER_RES:\n",
        "            continue\n",
        "\n",
        "\n",
        "        compression_results = compressor.compress(input_filepath)\n",
        "        reconstructed = compressor.decompress(compression_results)\n",
        "\n",
        "        original = compressor.original_pixel_data\n",
        "\n",
        "\n",
        "        psnr_val = psnr(original, reconstructed, data_range=1.0)\n",
        "        ssim_val = ssim(original, reconstructed, data_range=1.0)\n",
        "\n",
        "        abs_error = np.abs(original - reconstructed).flatten()\n",
        "\n",
        "        metrics_by_resolution[height]['psnr'].append(psnr_val)\n",
        "        metrics_by_resolution[height]['ssim'].append(ssim_val)\n",
        "        metrics_by_resolution[height]['compression_ratio'].append(\n",
        "            compression_results['compression_ratio']\n",
        "        )\n",
        "        metrics_by_resolution[height]['pixel_errors'].extend(abs_error.tolist())\n",
        "\n",
        "        image_count_by_resolution[height] += 1\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Skipping {input_filepath}: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\n=== Compression Performance & Per-Pixel Error Analysis ===\")\n",
        "\n",
        "for res in sorted(metrics_by_resolution.keys()):\n",
        "    stats = metrics_by_resolution[res]\n",
        "\n",
        "    if len(stats['psnr']) == 0:\n",
        "        continue\n",
        "\n",
        "    pixel_errors = np.array(stats['pixel_errors'])\n",
        "\n",
        "    print(f\"\\nResolution: {res} × {res}\")\n",
        "    print(f\"Images used: {len(stats['psnr'])}\")\n",
        "    print(f\"PSNR: {np.mean(stats['psnr']):.2f} ± {np.std(stats['psnr']):.2f} dB\")\n",
        "    print(f\"SSIM: {np.mean(stats['ssim']):.4f} ± {np.std(stats['ssim']):.4f}\")\n",
        "    print(f\"CR:   {np.mean(stats['compression_ratio']):.2f} ± {np.std(stats['compression_ratio']):.2f}\")\n",
        "\n",
        "    print(\"Per-Pixel Error Statistics:\")\n",
        "    print(f\"  Total pixels analyzed: {len(pixel_errors)}\")\n",
        "    print(f\"  Mean absolute error:   {np.mean(pixel_errors):.6f}\")\n",
        "    print(f\"  Max absolute error:    {np.max(pixel_errors):.6f}\")\n",
        "    print(f\"  95th percentile:      {np.percentile(pixel_errors, 95):.6f}\")\n",
        "    print(f\"  99th percentile:      {np.percentile(pixel_errors, 99):.6f}\")\n",
        "\n",
        "\n",
        "    if res in ERROR_PLOT_RES:\n",
        "        plt.figure(figsize=(6, 4))\n",
        "        plt.hist(pixel_errors, bins=100, log=True)\n",
        "        plt.xlabel(\"Absolute Reconstruction Error\")\n",
        "        plt.ylabel(\"Pixel Count (log scale)\")\n",
        "        plt.title(f\"Per-Pixel Error Distribution ({res}×{res})\")\n",
        "        plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "cw4T7hOWP0_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RUNTIME MEASUREMENT CELL\n",
        "import time\n",
        "import statistics\n",
        "from collections import defaultdict\n",
        "import cv2\n",
        "import oqs\n",
        "import secrets\n",
        "import pydicom\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def timed(fn, *args, **kwargs):\n",
        "    start = time.perf_counter()\n",
        "    out = fn(*args, **kwargs)\n",
        "    end = time.perf_counter()\n",
        "    return out, (end - start) * 1000.0\n",
        "\n",
        "\n",
        "runtime_by_size = defaultdict(lambda: {\n",
        "    'count': 0,\n",
        "    'compression_ms': [],\n",
        "    'mlkem_ms': [],\n",
        "    'encryption_ms': [],\n",
        "    'decryption_ms': [],\n",
        "    'total_ms': []\n",
        "})\n",
        "\n",
        "\n",
        "TARGET_RESOLUTIONS = {256, 800, 960}\n",
        "MAX_IMAGES_PER_SIZE = 10\n",
        "\n",
        "compressor = dcmCompressor(j2k_quality=90)\n",
        "encryptor = MedicalImageEncryptor()\n",
        "\n",
        "kem_receiver = oqs.KeyEncapsulation(\"ML-KEM-768\")\n",
        "pk_PQC = kem_receiver.generate_keypair()\n",
        "\n",
        "receiver_id = b\"Receiver-01\"\n",
        "\n",
        "\n",
        "for input_filepath in dicom_files:\n",
        "\n",
        "        dcm = pydicom.dcmread(input_filepath, force=True)\n",
        "        pixel_array = dcm.pixel_array.astype(np.float32)\n",
        "\n",
        "        height, width = pixel_array.shape[:2]\n",
        "\n",
        "\n",
        "        if height != width or height not in TARGET_RESOLUTIONS:\n",
        "            continue\n",
        "\n",
        "        image_size = (height, width)\n",
        "\n",
        "\n",
        "        if runtime_by_size[image_size]['count'] >= MAX_IMAGES_PER_SIZE:\n",
        "            continue\n",
        "\n",
        "\n",
        "        if all(runtime_by_size[(r, r)]['count'] >= MAX_IMAGES_PER_SIZE for r in TARGET_RESOLUTIONS):\n",
        "            break\n",
        "\n",
        "        t_total_start = time.perf_counter()\n",
        "\n",
        "\n",
        "        (_, t_comp) = timed(compressor.compress, input_filepath)\n",
        "        compression_results = compressor.compress(input_filepath)\n",
        "        reconstructed = compressor.decompress(compression_results)\n",
        "\n",
        "        nonce = secrets.token_bytes(16)\n",
        "\n",
        "        def kem_roundtrip():\n",
        "            kem_sender = oqs.KeyEncapsulation(\"ML-KEM-768\")\n",
        "            ct, ss = kem_sender.encap_secret(pk_PQC)\n",
        "            ss_rx = kem_receiver.decap_secret(ct)\n",
        "            return ss, ss_rx\n",
        "\n",
        "        ((shared_secret, shared_secret_rx), t_kem) = timed(kem_roundtrip)\n",
        "        assert shared_secret == shared_secret_rx\n",
        "\n",
        "        session_seed = derive_session_seed(shared_secret, nonce, receiver_id)\n",
        "        K_img = derive_image_key(session_seed, dcm)\n",
        "        chaos_params = map_key_to_chaos_params(K_img)\n",
        "\n",
        "        compressed_uint8 = cv2.normalize(\n",
        "            reconstructed, None, 0, 255, cv2.NORM_MINMAX\n",
        "        ).astype(np.uint8)\n",
        "\n",
        "        ((encrypted_img, _), t_enc) = timed(\n",
        "            encryptor.encrypt_image,\n",
        "            compressed_uint8,\n",
        "            key_params=chaos_params\n",
        "        )\n",
        "\n",
        "        (_, t_dec) = timed(\n",
        "            encryptor.decrypt_image,\n",
        "            encrypted_img,\n",
        "            chaos_params\n",
        "        )\n",
        "\n",
        "        t_total = (time.perf_counter() - t_total_start) * 1000.0\n",
        "\n",
        "        runtime_by_size[image_size]['count'] += 1\n",
        "        runtime_by_size[image_size]['compression_ms'].append(t_comp)\n",
        "        runtime_by_size[image_size]['mlkem_ms'].append(t_kem)\n",
        "        runtime_by_size[image_size]['encryption_ms'].append(t_enc)\n",
        "        runtime_by_size[image_size]['decryption_ms'].append(t_dec)\n",
        "        runtime_by_size[image_size]['total_ms'].append(t_total)\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\n================ RUNTIME PERFORMANCE (PER IMAGE SIZE) ================\\n\")\n",
        "\n",
        "for size in sorted(runtime_by_size.keys()):\n",
        "    vals = runtime_by_size[size]\n",
        "    if vals['count'] < 2:\n",
        "        continue\n",
        "\n",
        "    print(f\"Image size: {size[0]}×{size[1]}  |  N = {vals['count']}\")\n",
        "    print(f\"  Compression : {statistics.mean(vals['compression_ms']):.2f} ± {statistics.stdev(vals['compression_ms']):.2f} ms\")\n",
        "    print(f\"  ML-KEM      : {statistics.mean(vals['mlkem_ms']):.2f} ± {statistics.stdev(vals['mlkem_ms']):.2f} ms\")\n",
        "    print(f\"  Encryption  : {statistics.mean(vals['encryption_ms']):.2f} ± {statistics.stdev(vals['encryption_ms']):.2f} ms\")\n",
        "    print(f\"  Decryption  : {statistics.mean(vals['decryption_ms']):.2f} ± {statistics.stdev(vals['decryption_ms']):.2f} ms\")\n",
        "    print(f\"  End-to-End  : {statistics.mean(vals['total_ms']):.2f} ± {statistics.stdev(vals['total_ms']):.2f} ms\\n\")"
      ],
      "metadata": {
        "id": "6URa0l-XP3vd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  NIST SP800-22 TESTS\n",
        "import math\n",
        "\n",
        "\n",
        "def image_to_bitstream(img_uint8):\n",
        "    return ''.join(format(p, '08b') for p in img_uint8.flatten())\n",
        "\n",
        "\n",
        "\n",
        "def monobit_test(bits):\n",
        "    n = len(bits)\n",
        "    s = sum(1 if b == '1' else -1 for b in bits)\n",
        "    s_obs = abs(s) / math.sqrt(n)\n",
        "    p = math.erfc(s_obs / math.sqrt(2))\n",
        "    return p\n",
        "\n",
        "def block_frequency_test(bits, M=128):\n",
        "    n = len(bits)\n",
        "    N = n // M\n",
        "    chi_sq = 0\n",
        "    for i in range(N):\n",
        "        block = bits[i*M:(i+1)*M]\n",
        "        pi = block.count('1') / M\n",
        "        chi_sq += (pi - 0.5) ** 2\n",
        "    chi_sq *= 4 * M\n",
        "    p = math.exp(-chi_sq / 2)\n",
        "    return p\n",
        "\n",
        "def runs_test(bits):\n",
        "    n = len(bits)\n",
        "    pi = bits.count('1') / n\n",
        "    if abs(pi - 0.5) > 2 / math.sqrt(n):\n",
        "        return 0.0\n",
        "    runs = 1 + sum(bits[i] != bits[i-1] for i in range(1, n))\n",
        "    expected = 2 * n * pi * (1 - pi)\n",
        "    variance = 2 * n * pi * (1 - pi) * (2 * pi * (1 - pi) - 1)\n",
        "    z = abs(runs - expected) / math.sqrt(abs(variance))\n",
        "    p = math.erfc(z / math.sqrt(2))\n",
        "    return p\n",
        "\n",
        "def approximate_entropy_test(bits, m=2):\n",
        "    def phi(m):\n",
        "        counts = {}\n",
        "        for i in range(len(bits)):\n",
        "            pattern = bits[i:i+m]\n",
        "            if len(pattern) < m:\n",
        "                pattern += bits[:m-len(pattern)]\n",
        "            counts[pattern] = counts.get(pattern, 0) + 1\n",
        "        total = sum(counts.values())\n",
        "        return sum((v/total) * math.log(v/total) for v in counts.values())\n",
        "\n",
        "    apen = phi(m) - phi(m+1)\n",
        "    chi_sq = 2 * len(bits) * (math.log(2) - apen)\n",
        "    p = math.exp(-chi_sq / 2)\n",
        "    return p\n",
        "\n",
        "def serial_test(bits, m=2):\n",
        "    def count(m):\n",
        "        c = {}\n",
        "        for i in range(len(bits)):\n",
        "            pattern = bits[i:i+m]\n",
        "            if len(pattern) < m:\n",
        "                pattern += bits[:m-len(pattern)]\n",
        "            c[pattern] = c.get(pattern, 0) + 1\n",
        "        return c\n",
        "\n",
        "    c1 = count(m)\n",
        "    c2 = count(m-1)\n",
        "    psi1 = sum(v*v for v in c1.values()) * (2**m) / len(bits) - len(bits)\n",
        "    psi2 = sum(v*v for v in c2.values()) * (2**(m-1)) / len(bits) - len(bits)\n",
        "    delta = psi1 - psi2\n",
        "    p = math.exp(-delta / 2)\n",
        "    return p\n",
        "\n",
        "# ===================== RUN NIST TESTS =====================\n",
        "print(\"\\n==================== NIST SP800-22 RANDOMNESS TESTS ====================\")\n",
        "\n",
        "bitstream = image_to_bitstream(encrypted_img)\n",
        "\n",
        "nist_results = {\n",
        "    \"Monobit\": monobit_test(bitstream),\n",
        "    \"Block Frequency\": block_frequency_test(bitstream),\n",
        "    \"Runs\": runs_test(bitstream),\n",
        "    \"Approximate Entropy\": approximate_entropy_test(bitstream),\n",
        "    \"Serial\": serial_test(bitstream)\n",
        "}\n",
        "\n",
        "for test, pval in nist_results.items():\n",
        "    status = \"PASS\" if pval >= 0.01 else \"FAIL\"\n",
        "    print(f\"{test:22s} | p-value = {pval:.4f} | {status}\")\n"
      ],
      "metadata": {
        "id": "9x03FsI5P6ic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  UID COLLISION–BASED KEY SENSITIVITY TEST\n",
        "\n",
        "import hmac, hashlib, secrets, sys, oqs, cv2, numpy as np, matplotlib.pyplot as plt\n",
        "import pydicom\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr, structural_similarity as ssim\n",
        "\n",
        "def hkdf(ikm: bytes, salt: bytes, info: bytes, length=64):\n",
        "    prk = hmac.new(salt, ikm, hashlib.sha256).digest()\n",
        "    t = b\"\"\n",
        "    okm = b\"\"\n",
        "    c = 1\n",
        "    while len(okm) < length:\n",
        "        t = hmac.new(prk, t + info + bytes([c]), hashlib.sha256).digest()\n",
        "        okm += t\n",
        "        c += 1\n",
        "    return okm[:length]\n",
        "\n",
        "def derive_session_seed(shared_secret, nonce, receiver_id):\n",
        "    return hkdf(shared_secret, nonce, receiver_id, 32)\n",
        "\n",
        "def derive_image_key(session_seed, dcm):\n",
        "    uid_blob = (\n",
        "        dcm.StudyInstanceUID +\n",
        "        dcm.SeriesInstanceUID +\n",
        "        dcm.SOPInstanceUID +\n",
        "        dcm.SOPClassUID\n",
        "    ).encode()\n",
        "    return hkdf(session_seed, b\"DICOM\", uid_blob, 64)\n",
        "\n",
        "def map_key_to_chaos_params(K_img):\n",
        "    v = [int.from_bytes(K_img[i:i+4], 'big') for i in range(0, 36, 4)]\n",
        "    return {\n",
        "        'x0': 0.1 + (v[0] % 1000) / 10000,\n",
        "        'y0': 0.1 + (v[1] % 1000) / 10000,\n",
        "        'z0': 0.1 + (v[2] % 1000) / 10000,\n",
        "        'w0': 0.1 + (v[3] % 1000) / 10000,\n",
        "        'a': 35.0 + (v[4] % 50) / 10,\n",
        "        'b': 3.0 + (v[5] % 10) / 10,\n",
        "        'c': 12.0 + (v[6] % 20) / 10,\n",
        "        'd': 7.0 + (v[7] % 10) / 10,\n",
        "        'e': 0.1 + (v[8] % 10) / 100\n",
        "    }\n",
        "\n",
        "\n",
        "def compute_npcr_uaci(C1, C2):\n",
        "    diff = C1 != C2\n",
        "    npcr = np.sum(diff) / diff.size * 100\n",
        "    uaci = np.mean(np.abs(C1.astype(np.float32) - C2.astype(np.float32)) / 255) * 100\n",
        "    return npcr, uaci\n",
        "\n",
        "\n",
        "print(\" UID Collision–Based Key Sensitivity Test\")\n",
        "\n",
        "input_filepath = \"image path\"\n",
        "dcm = pydicom.dcmread(input_filepath, force=True)\n",
        "\n",
        "compressor = dcmCompressor(j2k_quality=90)\n",
        "encryptor = MedicalImageEncryptor()\n",
        "\n",
        "\n",
        "compression_results = compressor.compress(input_filepath)\n",
        "reconstructed = compressor.decompress(compression_results)\n",
        "\n",
        "compressed_uint8 = cv2.normalize(\n",
        "    reconstructed, None, 0, 255, cv2.NORM_MINMAX\n",
        ").astype(np.uint8)\n",
        "\n",
        "\n",
        "kem_receiver = oqs.KeyEncapsulation(\"ML-KEM-768\")\n",
        "pk = kem_receiver.generate_keypair()\n",
        "\n",
        "kem_sender = oqs.KeyEncapsulation(\"ML-KEM-768\")\n",
        "ct, shared_secret = kem_sender.encap_secret(pk)\n",
        "shared_secret_rx = kem_receiver.decap_secret(ct)\n",
        "\n",
        "assert shared_secret == shared_secret_rx\n",
        "\n",
        "nonce = secrets.token_bytes(16)\n",
        "receiver_id = b\"Receiver-01\"\n",
        "session_seed = derive_session_seed(shared_secret, nonce, receiver_id)\n",
        "\n",
        "\n",
        "K_img_1 = derive_image_key(session_seed, dcm)\n",
        "params_1 = map_key_to_chaos_params(K_img_1)\n",
        "\n",
        "cipher_1, _ = encryptor.encrypt_image(compressed_uint8, key_params=params_1)\n",
        "\n",
        "\n",
        "dcm_uid_perturbed = dcm.copy()\n",
        "dcm_uid_perturbed.SOPInstanceUID = dcm.SOPInstanceUID[:-1] + (\n",
        "    \"1\" if dcm.SOPInstanceUID[-1] != \"1\" else \"2\"\n",
        ")\n",
        "\n",
        "K_img_2 = derive_image_key(session_seed, dcm_uid_perturbed)\n",
        "params_2 = map_key_to_chaos_params(K_img_2)\n",
        "\n",
        "cipher_2, _ = encryptor.encrypt_image(compressed_uint8, key_params=params_2)\n",
        "\n",
        "\n",
        "npcr, uaci = compute_npcr_uaci(cipher_1, cipher_2)\n",
        "\n",
        "print(\"\\n==================== UID SENSITIVITY RESULTS ====================\")\n",
        "print(f\"SOPInstanceUID change: 1 digit\")\n",
        "print(f\"NPCR : {npcr:.4f}%\")\n",
        "print(f\"UACI : {uaci:.4f}%\")\n",
        "print(f\"Key hash 1: {hashlib.sha256(K_img_1).hexdigest()[:16]}...\")\n",
        "print(f\"Key hash 2: {hashlib.sha256(K_img_2).hexdigest()[:16]}...\")\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(cipher_1, cmap='gray')\n",
        "plt.title(\"Ciphertext (Original UID)\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(cipher_2, cmap='gray')\n",
        "plt.title(\"Ciphertext (Perturbed UID)\")\n",
        "plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mRVjIMMXP9id"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#security analysis\n"
      ],
      "metadata": {
        "id": "XSfyUPDAKMTz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_difference_maps_from_pipeline(original_plain, encryptor, fixed_keys):\n",
        "\n",
        "    plain1 = original_plain.copy()\n",
        "    plain2 = original_plain.copy()\n",
        "\n",
        "    # Safe minimal modification (no overflow)\n",
        "    if plain2[0, 0] < 255:\n",
        "        plain2[0, 0] += 1\n",
        "    else:\n",
        "        plain2[0, 0] -= 1\n",
        "\n",
        "    cipher1, _ = encryptor.encrypt_image(plain1, key_params=fixed_keys)\n",
        "    cipher2, _ = encryptor.encrypt_image(plain2, key_params=fixed_keys)\n",
        "\n",
        "    plaintext_diff = np.abs(plain1.astype(np.int16) - plain2.astype(np.int16))\n",
        "    ciphertext_diff = np.abs(cipher1.astype(np.int16) - cipher2.astype(np.int16))\n",
        "\n",
        "    plt.figure(figsize=(10, 4))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(plaintext_diff, cmap='hot')\n",
        "    plt.colorbar(fraction=0.046, pad=0.04)\n",
        "    plt.title(\"(a) Plaintext Difference Map\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(ciphertext_diff, cmap='hot')\n",
        "    plt.colorbar(fraction=0.046, pad=0.04)\n",
        "    plt.title(\"(b) Ciphertext Difference Map\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.suptitle(\"Difference Maps Under Known-Plaintext Scenario\", fontsize=12)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_difference_maps_from_pipeline(\n",
        "    compressed_uint8,\n",
        "    encryptor,\n",
        "    fixed_keys\n",
        ")\n"
      ],
      "metadata": {
        "id": "kFGOPbPqQAab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import io\n",
        "import cv2\n",
        "\n",
        "def plot_encrypted_primary_vs_residual_histograms(\n",
        "    compression_results,\n",
        "    compressor,\n",
        "    encryptor,\n",
        "    fixed_keys\n",
        "):\n",
        "    \"\"\"\n",
        "    Plot histogram comparison between encrypted primary and encrypted residual streams.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    primary_img = np.array(\n",
        "        Image.open(io.BytesIO(compression_results['j2k_primary']))\n",
        "    ).astype(np.float32)\n",
        "\n",
        "    primary_img = compressor._normalize_pixel_data(\n",
        "        primary_img, compressor.metadata['BitsStored']\n",
        "    )\n",
        "    primary_uint8 = cv2.normalize(primary_img, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
        "\n",
        "\n",
        "    residual_img = np.array(\n",
        "        Image.open(io.BytesIO(compression_results['j2k_residual']))\n",
        "    ).astype(np.float32)\n",
        "\n",
        "    residual_img = cv2.normalize(residual_img, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
        "\n",
        "\n",
        "    encrypted_primary, _ = encryptor.encrypt_image(primary_uint8, key_params=fixed_keys)\n",
        "    encrypted_residual, _ = encryptor.encrypt_image(residual_img, key_params=fixed_keys)\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(10, 4))\n",
        "\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.hist(encrypted_primary.flatten(), bins=256, range=(0, 255), color='gray')\n",
        "    plt.title(\"(a) Encrypted Primary Stream\")\n",
        "    plt.xlabel(\"Pixel Intensity\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.hist(encrypted_residual.flatten(), bins=256, range=(0, 255), color='gray')\n",
        "    plt.title(\"(b) Encrypted Residual Stream\")\n",
        "    plt.xlabel(\"Pixel Intensity\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "\n",
        "    plt.suptitle(\"Histogram Comparison of Encrypted Primary and Residual Streams\", fontsize=12)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "plot_encrypted_primary_vs_residual_histograms(\n",
        "    compression_results,\n",
        "    compressor,\n",
        "    encryptor,\n",
        "    fixed_keys\n",
        ")\n"
      ],
      "metadata": {
        "id": "TWHZ7a69QCts"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}